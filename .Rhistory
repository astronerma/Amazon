train <- read.csv(file="./Data/train.csv")
test <- read.csv(file="./Data/test.csv")
source("../Utils/submission_utils.R")
iteration = 9
library("e1071")
library("hash")
library("verification")
# Concatenate columns 2-10 in training set
new_train <- as.data.frame(matrix(NA, ncol=2,nrow=nrow(train)))
new_train[[1]] <- train[[1]]
new_train[[2]]<-apply(train,1,function(x) paste(x[2],x[4],x[5],x[6],x[7],x[8],x[9],x[10],sep="-"))
new_train[[2]] <- as.factor(new_train[[2]])
View(new_train)
setwd("/Users/aszostek/Projects/Kaggle/Amazon")
train <- read.csv(file="./Data/train.csv")
test <- read.csv(file="./Data/test.csv")
# Remove redundant column
train <- train[,c(-10)]
test <- test[,c(-10)]
source("../Utils/submission_utils.R")
iteration = 12
library("e1071")
library("hash")
library("verification")
library('Matrix')
library('glmnet')
# Lets first transform the data to later be able to create the sparse matrix
new_train <- train
new_test <- test
# Rename each variable
transform_column<-function(sufix,column,dataframe)
{
dataframe[[column]]<-lapply(dataframe[[column]],function(x) paste(as.character(x),sufix,sep=""))
return(dataframe)
}
new_train<-transform_column("c2",2,new_train)
new_train<-transform_column("c3",3,new_train)
new_train<-transform_column("c4",4,new_train)
new_train<-transform_column("c5",5,new_train)
new_train<-transform_column("c6",6,new_train)
new_train<-transform_column("c7",7,new_train)
new_train<-transform_column("c8",8,new_train)
new_train<-transform_column("c9",9,new_train)
new_test<-transform_column("c2",2,new_test)
new_test<-transform_column("c3",3,new_test)
new_test<-transform_column("c4",4,new_test)
new_test<-transform_column("c5",5,new_test)
new_test<-transform_column("c6",6,new_test)
new_test<-transform_column("c7",7,new_test)
new_test<-transform_column("c8",8,new_test)
new_test<-transform_column("c9",9,new_test)
# Train and test combined
all <- rbind(new_train[,2:9],new_test[,2:9])
slownik <- hash()
uniquew <- c(
unique(all[[1]]),
unique(all[[2]]),
unique(all[[3]]),
unique(all[[4]]),
unique(all[[5]]),
unique(all[[6]]),
unique(all[[7]]),
unique(all[[8]])
)
# Slownik of all unique codes each keeps its corresponding collumn number!
i<-1
for (word in uniquew)
{
print (i)
slownik[[word]] <- i
i <- i + 1
}
keymax <- length(keys(slownik))
# Lets put this slownik into a data frame
# to be able to do a match
data_slownik <- as.data.frame(matrix(NA,ncol=2,nrow=keymax))
k <- keys(slownik)
for (i in k)
{
row <- slownik[[i]]
data_slownik[row,1] <- row
data_slownik[row,2] <- i
}
trans_train <- new_train
trans_train[[2]] <- data_slownik[match(new_train[[2]],data_slownik[[2]]),1]
trans_train[[3]] <- data_slownik[match(new_train[[3]],data_slownik[[2]]),1]
trans_train[[4]] <- data_slownik[match(new_train[[4]],data_slownik[[2]]),1]
trans_train[[5]] <- data_slownik[match(new_train[[5]],data_slownik[[2]]),1]
trans_train[[6]] <- data_slownik[match(new_train[[6]],data_slownik[[2]]),1]
trans_train[[7]] <- data_slownik[match(new_train[[7]],data_slownik[[2]]),1]
trans_train[[8]] <- data_slownik[match(new_train[[8]],data_slownik[[2]]),1]
trans_train[[9]] <- data_slownik[match(new_train[[9]],data_slownik[[2]]),1]
View(trans_train)
setwd("/Users/aszostek/Projects/Kaggle/Amazon")
train <- read.csv(file="./Data/train.csv")
test <- read.csv(file="./Data/test.csv")
# Remove redundant column
train <- train[,c(-10)]
test <- test[,c(-10)]
source("../Utils/submission_utils.R")
iteration = 13
library("tree")
library("e1071")
library("hash")
library("verification")
library('Matrix')
# ---------------
# My new datasets
new_train <- as.data.frame(matrix(NA,nrow = nrow(train),ncol=17))
names(new_train) <- c("action","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1")
new_train[[1]] <- train[[1]]
new_test <- as.data.frame(matrix(NA,nrow = nrow(test),ncol=17))
names(new_test) <- c("id","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1")
new_test[[1]] <- test[[1]]
for (col in 2:9)
{
print(col)
c0 <- 2*col-2
c1 <- 2*col-1
uni <- unique(train[[col]])
uni_test <- unique(test[[col]])
diff <- setdiff(uni_test,uni)
slownik0 <- hash(uni,rep(0,length(uni)))
slownik1 <- hash(uni,rep(0,length(uni)))
# populate slownik
for (row in 1:nrow(train))
{
if (train[row,1] == 1)
{
slownik1[[ as.character(train[row,col]) ]] <- slownik1[[ as.character(train[row,col]) ]] + 1
}
else
{
slownik0[[ as.character(train[row,col]) ]] <- slownik0[[ as.character(train[row,col]) ]] + 1
}
}
# populate new_train
tmp <- as.data.frame(matrix(NA,nrow = length(uni),ncol=3))
for (row in 1:length(uni))
{
#print(row)
word <- uni[row]
s0 <- slownik0[[as.character(word)]]
s1 <- slownik1[[as.character(word)]]
tmp[row,1] <- word
tmp[row,2] <- s0/(s0+s1)
tmp[row,3] <- s1/(s0+s1)
}
new_train[[c0]] <- tmp[match(train[[col]],tmp[[1]]),2]
new_train[[c1]] <- tmp[match(train[[col]],tmp[[1]]),3]
new_test[[c0]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),2]
new_test[[c1]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),3]
}
system("say done")
View(new_test)
setwd("/Users/aszostek/Projects/Kaggle/Amazon")
train <- read.csv(file="./Data/train.csv")
test <- read.csv(file="./Data/test.csv")
source("../Utils/submission_utils.R")
iteration = 20
library("e1071")
library("hash")
library("verification")
# Concatenate columns 2-10 in training set
new_train <- as.data.frame(matrix(NA, ncol=2,nrow=nrow(train)))
new_train[[1]] <- train[[1]]
new_train[[2]]<-apply(train,1,function(x) paste(x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],sep="-"))
#new_train[[2]] <- as.factor(new_train[[2]])
# Make the same concatenation for test set
new_test <- as.data.frame(matrix(NA, ncol=2,nrow=nrow(test)))
new_test[[1]] <- test[[1]]
new_test[[2]] <- apply(test,1,function(x) paste(x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],sep="-"))
# Now do a pivot
mean_action <- aggregate(new_train[[1]],list(new_train[[2]]),mean)
m <- mean(mean_action[[2]])
prediction_train <- mean_action[match(new_train[[2]],mean_action[[1]]),2]
roc.area(train[[1]], prediction_train)
roc.area(train[[1]], prediction_train)$A
submission <- read.csv(file="./Submissions/submission19.csv")
prediction_test <- mean_action[match(new_test[[2]],mean_action[[1]]),2]
sum(is.na(prediction_test))
prediction_test[is.na(prediction_test)] <- submission[is.na(prediction_test),2]
id <- test[[1]]
prediction <- prediction_test
test_submission<-as.data.frame(matrix(data = NA, nrow = length(prediction),ncol=2))
test_submission[[1]] <- id
test_submission[[2]] <- prediction
names(test_submission)<-c("Id","Action")
submission_file_name = paste("./Submissions/submission",as.character(iteration),".csv",sep="")
submission_file_name
write.csv(test_submission,file=submission_file_name,row.names=FALSE,quote=FALSE)
diffsub(19,20,2,"Amazon")
setwd("/Users/aszostek/Projects/Kaggle/Amazon")
train <- read.csv(file="./Data/train.csv")
test <- read.csv(file="./Data/test.csv")
# Remove redundant column
train <- train[,c(-10)]
test <- test[,c(-10)]
source("../Utils/submission_utils.R")
iteration = 21
library("randomForest")
library("tree")
library("e1071")
library("hash")
library("verification")
library('glmnet')
new_feature_sets <- function(train,test)
{
# ---------------
# My new datasets
new_train <- as.data.frame(matrix(NA,nrow = nrow(train),ncol=25))
names(new_train) <- c("action","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1","Nresource","Nmgr","role1","role2","dept","title","family","role")
new_train[[1]] <- train[[1]]
new_test <- as.data.frame(matrix(NA,nrow = nrow(test),ncol=25))
names(new_test) <- c("id","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1","Nresource","Nmgr","role1","role2","dept","title","family","role")
new_test[[1]] <- test[[1]]
for(col in 2:ncol(train))
{
#print(col)
c0 <- 2*col-2
c1 <- 2*col-1
c2 <- 17+col-1
uni <- unique(train[[col]])
uni_test <- unique(test[[col]])
diff <- setdiff(uni_test,uni)
slownik0 <- hash(uni,rep(0,length(uni)))
slownik1 <- hash(uni,rep(0,length(uni)))
# populate slownik
for (row in 1:nrow(train))
{
if (train[row,1] == 1)
{
slownik1[[ as.character(train[row,col]) ]] <- slownik1[[ as.character(train[row,col]) ]] + 1
}
else
{
slownik0[[ as.character(train[row,col]) ]] <- slownik0[[ as.character(train[row,col]) ]] + 1
}
}
# populate new_train and new_test
tmp <- as.data.frame(matrix(NA,nrow = length(uni),ncol=4))
for (row in 1:length(uni))
{
#print(row)
word <- uni[row]
s0 <- slownik0[[as.character(word)]]
s1 <- slownik1[[as.character(word)]]
tmp[row,1] <- word
tmp[row,2] <- s0/(s0+s1)
tmp[row,3] <- s1/(s0+s1)
tmp[row,4] <- s0+s1
}
new_train[[c0]] <- tmp[match(train[[col]],tmp[[1]]),2]
new_train[[c1]] <- tmp[match(train[[col]],tmp[[1]]),3]
new_train[[c2]] <- tmp[match(train[[col]],tmp[[1]]),4]
new_test[[c0]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),2]
new_test[[c1]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),3]
new_test[[c2]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),4]
}
new_test <- as.data.frame(impute(new_test,"median"))
log_train<-new_train
log_train[,2:17]<-log10(new_train[,2:17]+1e-3)
log_train[[1]] <- as.factor(log_train[[1]])
log_test <- new_test
log_test[,2:17]<-log10(new_test[,2:17]+1e-3)
log_test[[1]] <- as.factor(log_test[[1]])
return(list(log_train,log_test))
} # end
new_data <- new_feature_sets(train,test)
system("say done")
log_train <- new_data[[1]]
log_test <- new_data[[2]]
View(log_test)
hist(log_train[[18]])
hist(log10(log_train[[18]]))
hist(log_train[[18]])
by(train[[1]],train[[2]],sum)
train[log_train$Nresource==839,2]
sum(train[train$RESOURCE=4675,1]
sum(train[train$RESOURCE==4675,1]
)
unique(train[[4]])
View(train)
sum(train[train$ROLE_ROLLUP_1==117961,1]
)
sum(train[train$ROLE_ROLLUP_1==117961,1])
t2 <- glm(action ~.,data=log_train,family="binomial")
new_feature_sets <- function(train,test)
{
# ---------------
# My new datasets
new_train <- as.data.frame(matrix(NA,nrow = nrow(train),ncol=25))
names(new_train) <- c("action","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1","Nresource","Nmgr","Nrole1","Nrole2","Ndept","Ntitle","Nfamily","Nrole")
new_train[[1]] <- train[[1]]
new_test <- as.data.frame(matrix(NA,nrow = nrow(test),ncol=25))
names(new_test) <- c("id","resource0","resource1","mgr0","mgr1","role1_0","role1_1","role2_0", "role2_1", "dept0","dept1","title0","title1","family0","family1","role0","role1","Nresource","Nmgr","Nrole1","Nrole2","Ndept","Ntitle","Nfamily","Nrole")
new_test[[1]] <- test[[1]]
for(col in 2:ncol(train))
{
#print(col)
c0 <- 2*col-2
c1 <- 2*col-1
c2 <- 17+col-1
uni <- unique(train[[col]])
uni_test <- unique(test[[col]])
diff <- setdiff(uni_test,uni)
slownik0 <- hash(uni,rep(0,length(uni)))
slownik1 <- hash(uni,rep(0,length(uni)))
# populate slownik
for (row in 1:nrow(train))
{
if (train[row,1] == 1)
{
slownik1[[ as.character(train[row,col]) ]] <- slownik1[[ as.character(train[row,col]) ]] + 1
}
else
{
slownik0[[ as.character(train[row,col]) ]] <- slownik0[[ as.character(train[row,col]) ]] + 1
}
}
# populate new_train and new_test
tmp <- as.data.frame(matrix(NA,nrow = length(uni),ncol=4))
for (row in 1:length(uni))
{
#print(row)
word <- uni[row]
s0 <- slownik0[[as.character(word)]]
s1 <- slownik1[[as.character(word)]]
tmp[row,1] <- word
tmp[row,2] <- s0/(s0+s1)
tmp[row,3] <- s1/(s0+s1)
tmp[row,4] <- s0+s1
}
new_train[[c0]] <- tmp[match(train[[col]],tmp[[1]]),2]
new_train[[c1]] <- tmp[match(train[[col]],tmp[[1]]),3]
new_train[[c2]] <- tmp[match(train[[col]],tmp[[1]]),4]
new_test[[c0]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),2]
new_test[[c1]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),3]
new_test[[c2]] <- tmp[match(test[[col]],tmp[[1]],incomparables=diff,nomatch=NA),4]
}
new_test <- as.data.frame(impute(new_test,"median"))
log_train<-new_train
log_train[,2:17]<-log10(new_train[,2:17]+1e-3)
log_train[[1]] <- as.factor(log_train[[1]])
log_test <- new_test
log_test[,2:17]<-log10(new_test[,2:17]+1e-3)
log_test[[1]] <- as.factor(log_test[[1]])
return(list(log_train,log_test))
} # end
new_data <- new_feature_sets(train,test)
system("say done")
log_train <- new_data[[1]]
log_test <- new_data[[2]]
View(log_train)
t2 <- glm(action ~.,data=log_train,family="binomial")
summary(t2)
predict_train <- predict(t2,type="response")
roc.area(train[[1]], predict_train)$A
kfold.glm<-function(data,k,cols)
{
s<-sample(1:nrow(data),nrow(data),replace=FALSE)
n<-as.integer(nrow(data)/k)
err.vect<-rep(NA,k)
for (i in 1:k)
{
print (i)
print(cols)
# Prepare new training and test set
s1<-((i-1)*n+1)
s2<-(i*n)
subset<-s[s1:s2]
#print(subset[1:10])
train<-data[-subset,]
test<-data[subset,]
# Generate new features
new_data <- new_feature_sets(train,test)
log_train <- new_data[[1]]
log_test <- new_data[[2]]
# Make a fit
fit <- glm(action ~.,data=log_train[,cols],family="binomial")
prediction <- predict(fit,newdata=log_test[,cols],type="response")
#fit <- tree(action ~.,data=log_train[,cols])
#prediction <- predict(fit,newdata=log_test[,cols],type="vector")[,2]
labels <- as.numeric(as.character(log_test[[1]]))
err <- roc.area(labels,prediction)$A
err.vect[i]<-err
}
return(err.vect)
}
kfold.glmnet<-function(data,k,cols,lambda)
{
s<-sample(1:nrow(data),nrow(data),replace=FALSE)
n<-as.integer(nrow(data)/k)
err.vect<-rep(NA,k)
for (i in 1:k)
{
print (i)
#print(cols)
# Prepare new training and test set
s1<-((i-1)*n+1)
s2<-(i*n)
subset<-s[s1:s2]
train<-data[-subset,]
test<-data[subset,]
# Generate new features
new_data <- new_feature_sets(train,test)
log_train <- new_data[[1]]
log_test <- new_data[[2]]
# Make a fit
fit <- glm(action ~.,data=log_train[,cols],family="binomial")
prediction <- predict(fit,newdata=log_test[,cols],type="response")
#fit <- glmnet(as.matrix(log_train[,2:17]),log_train[[1]],family="binomial")
#prediction <- as.numeric(predict(fit, as.matrix(log_test[,2:17]) ,type="link",s=lambda))
labels <- as.numeric(as.character(log_test[[1]]))
err <- roc.area(labels,prediction)$A
err.vect[i]<-err
}
return(err.vect)
}
a<-kfold.glm(train,3,1:25)
a
system("say done")
563/1500
t2 <- glm(action ~.,data=log_train,family="binomial")
summary(t2)
t2 <- glm(action ~.,data=log_train[,c(1,2,3,4,5,12,14,17,,20)],family="binomial")
t2 <- glm(action ~.,data=log_train[,c(1,2,3,4,5,12,14,17,20)],family="binomial")
summary(t2)
predict_train <- predict(t2,type="response")
roc.area(train[[1]], predict_train)$A
a<-kfold.glm(train,3,c(1,2,3,4,5,12,14,17,20))
a
system("say done")
t2 <- glm(action ~.,data=log_train[,c(1,2,3,4,5,12,14,17,20)],family="binomial",intercep=F)
t2 <- glm(action ~.,data=log_train[,c(1,2,3,4,5,12,14,17,20)],family="binomial",intercept=F)
t2 <- glm(action ~.,data=log_train[,c(1,2,3,4,5,12,14,17,20)],family="binomial",epsilon=1e-9)
summary(t2)
predict_train <- predict(t2,type="response")
#predict_train
roc.area(train[[1]], predict_train)$A
kfold.glm<-function(data,k,cols)
{
s<-sample(1:nrow(data),nrow(data),replace=FALSE)
n<-as.integer(nrow(data)/k)
err.vect<-rep(NA,k)
for (i in 1:k)
{
print (i)
print(cols)
# Prepare new training and test set
s1<-((i-1)*n+1)
s2<-(i*n)
subset<-s[s1:s2]
#print(subset[1:10])
train<-data[-subset,]
test<-data[subset,]
# Generate new features
new_data <- new_feature_sets(train,test)
log_train <- new_data[[1]]
log_test <- new_data[[2]]
# Make a fit
fit <- glm(action ~.,data=log_train[,cols],family="binomial",epsilon=1e-9)
prediction <- predict(fit,newdata=log_test[,cols],type="response")
#fit <- tree(action ~.,data=log_train[,cols])
#prediction <- predict(fit,newdata=log_test[,cols],type="vector")[,2]
labels <- as.numeric(as.character(log_test[[1]]))
err <- roc.area(labels,prediction)$A
err.vect[i]<-err
}
return(err.vect)
}
a<-kfold.glm(train,3,c(1,2,3,4,5,12,14,17,20))
a
system("say done")
kfold.glm<-function(data,k,cols)
{
s<-sample(1:nrow(data),nrow(data),replace=FALSE)
n<-as.integer(nrow(data)/k)
err.vect<-rep(NA,k)
for (i in 1:k)
{
print (i)
print(cols)
# Prepare new training and test set
s1<-((i-1)*n+1)
s2<-(i*n)
subset<-s[s1:s2]
#print(subset[1:10])
train<-data[-subset,]
test<-data[subset,]
# Generate new features
new_data <- new_feature_sets(train,test)
log_train <- new_data[[1]]
log_test <- new_data[[2]]
# Make a fit
fit <- glm(action ~.,data=log_train[,cols],family="binomial",epsilon=1e-9,maxit=35)
prediction <- predict(fit,newdata=log_test[,cols],type="response")
#fit <- tree(action ~.,data=log_train[,cols])
#prediction <- predict(fit,newdata=log_test[,cols],type="vector")[,2]
labels <- as.numeric(as.character(log_test[[1]]))
err <- roc.area(labels,prediction)$A
err.vect[i]<-err
}
return(err.vect)
}
a<-kfold.glm(train,3,c(1,2,3,4,5,12,14,17,20))
a
system("say done")
a<-kfold.glm(train,5,c(1,2,3,4,5,12,14,17,20))
a
system("say done")
View(log_train)
